{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "import pytorch_wavelets.dwt.lowlevel as lowlevel\n",
    "import pywt\n",
    "from rich.console import Console\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWTForward(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies a single-level 2D Discrete Wavelet Transform using Haar wavelets.\n",
    "    Returns:\n",
    "        LL: Low-frequency component\n",
    "        HF: High-frequency components concatenated along channel dimension\n",
    "    \"\"\"\n",
    "    def __init__(self, wave=\"haar\", mode=\"zero\"):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "\n",
    "        # Wavelet filter coefficients\n",
    "        h0_col, h1_col = wave.dec_lo, wave.dec_hi\n",
    "        h0_row, h1_row = h0_col, h1_col\n",
    "\n",
    "        # Prepare filter banks (pytorch_wavelets)\n",
    "        filts = lowlevel.prep_filt_afb2d(h0_col, h1_col, h0_row, h1_row)\n",
    "\n",
    "        self.register_buffer(\"h0_col\", filts[0])\n",
    "        self.register_buffer(\"h1_col\", filts[1])\n",
    "        self.register_buffer(\"h0_row\", filts[2])\n",
    "        self.register_buffer(\"h1_row\", filts[3])\n",
    "\n",
    "        self.mode = lowlevel.mode_to_int(mode)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ll = low frequency      shape -> [B, C, H/2, W/2]\n",
    "        # high = tensor of [LH, HL, HH] concatenated -> [B, 3*C, H/2, W/2]\n",
    "        ll, high = lowlevel.AFB2D.apply(\n",
    "            x, self.h0_col, self.h1_col, self.h0_row, self.h1_row, self.mode\n",
    "        )\n",
    "        return ll, high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLFFE_Frame(nn.Module):\n",
    "    \"\"\"\n",
    "    Extracts a 512-dimensional frequency feature vector for a single frame.\n",
    "    Consists of:\n",
    "        - Initial CNN embedding\n",
    "        - 3-level hierarchical Haar DWT\n",
    "        - Concatenation of all levels (LL + HF)\n",
    "        - Final classifier -> 512-dim feature\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_ch=64):\n",
    "        super().__init__()\n",
    "\n",
    "        # Shallow image embedding\n",
    "        self.conv = nn.Conv2d(3, embed_ch, kernel_size=3, padding=1)\n",
    "\n",
    "        # DWT operator (Haar)\n",
    "        self.dwt = DWTForward(wave=\"haar\")\n",
    "\n",
    "        # Each level is pooled to 7×7 \n",
    "        self.pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        # (LL + LH + HL + HH) * 3 levels = 12 × C channels\n",
    "        total_channels = embed_ch * 12\n",
    "\n",
    "        # Final linear mapper -> 512 dims\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm2d(total_channels),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.LayerNorm(total_channels * 3 * 3),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(total_channels * 3 * 3, 512),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        \"\"\"\n",
    "        img: [B, 3, 224, 224]\n",
    "        return: [B, 512]\n",
    "        \"\"\"\n",
    "        x = self.conv(img)\n",
    "        b, c, h, w = x.shape\n",
    "\n",
    "        # ---- Level 1 ----\n",
    "        LL1, HF1 = self.dwt(x)\n",
    "        HF1 = HF1.view(b, 3 * c, h // 2, w // 2)\n",
    "        X1 = self.pool(torch.cat([LL1, HF1], dim=1))\n",
    "\n",
    "        # ---- Level 2 ----\n",
    "        LL2, HF2 = self.dwt(LL1)\n",
    "        HF2 = HF2.view(b, 3 * c, h // 4, w // 4)\n",
    "        X2 = self.pool(torch.cat([LL2, HF2], dim=1))\n",
    "\n",
    "        # ---- Level 3 ----\n",
    "        LL3, HF3 = self.dwt(LL2)\n",
    "        HF3 = HF3.view(b, 3 * c, h // 8, w // 8)\n",
    "        X3 = self.pool(torch.cat([LL3, HF3], dim=1))\n",
    "\n",
    "        # Combine all 3 levels\n",
    "        X = torch.cat([X1, X2, X3], dim=1)\n",
    "\n",
    "        feat = self.classifier(X)\n",
    "        return feat   # shape: [B, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoMLFFE(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies ML-FFE on all frames of a video.\n",
    "    Input:  [B, T, 3, 224, 224]\n",
    "    Output: [B, T, 512]      512-D feature per frame (for temporal models)\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_ch=64):\n",
    "        super().__init__()\n",
    "        self.frame_model = MLFFE_Frame(embed_ch)\n",
    "\n",
    "    def forward(self, videos):\n",
    "        \"\"\"\n",
    "        videos: [Batch, Frames, 3, 224, 224]\n",
    "        returns:\n",
    "            frame_feats: [B, T, 512]\n",
    "        \"\"\"\n",
    "        B, T, C, H, W = videos.shape\n",
    "\n",
    "        # Vectorized processing: flatten batch & time\n",
    "        frames = videos.view(B * T, C, H, W)    # [B*T, 3, 224, 224]\n",
    "\n",
    "        # Extract per-frame features\n",
    "        feats = self.frame_model(frames)        # [B*T, 512]\n",
    "\n",
    "        # Restore temporal structure\n",
    "        frame_feats = feats.view(B, T, 512)\n",
    "\n",
    "        return frame_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m VideoMLFFE(embed_ch\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m      4\u001b[0m B, T \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m\n\u001b[0;32m      5\u001b[0m dummy \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(B, T, \u001b[39m3\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[39m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[39m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(\n\u001b[0;32m   1327\u001b[0m         device,\n\u001b[0;32m   1328\u001b[0m         dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1329\u001b[0m         non_blocking,\n\u001b[0;32m   1330\u001b[0m     )\n\u001b[0;32m   1331\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(e) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCannot copy out of meta tensor; no data!\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VideoMLFFE(embed_ch=64).to(device)\n",
    "\n",
    "B, T = 1, 64\n",
    "dummy = torch.randn(B, T, 3, 224, 224).to(device)\n",
    "\n",
    "out = model(dummy)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==========================================================================================\n",
       "Layer <span style=\"font-weight: bold\">(</span>typ<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:de</span>pth-idx<span style=\"font-weight: bold\">)</span>                   Param #                   Kernel Shape\n",
       "==========================================================================================\n",
       "MLFFE_Frame                              --                        --\n",
       "├─Conv2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">792</span>                     <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span>\n",
       "├─DWTForward: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                        --                        --\n",
       "├─AdaptiveAvgPool2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                 --                        --\n",
       "├─Sequential: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                        --                        --\n",
       "│    └─BatchNorm2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">536</span>                     --\n",
       "│    └─MaxPool2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                    --                        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "│    └─Flatten: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                      --                        --\n",
       "│    └─LayerNorm: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">824</span>                    --\n",
       "│    └─Dropout: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                      --                        --\n",
       "│    └─PReLU: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>                        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                         --\n",
       "│    └─Linear: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">539</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">456</span>                 --\n",
       "==========================================================================================\n",
       "Total params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">556</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">609</span>\n",
       "Trainable params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">556</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">609</span>\n",
       "Non-trainable params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "==========================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==========================================================================================\n",
       "Layer \u001b[1m(\u001b[0mtyp\u001b[1;92me:de\u001b[0mpth-idx\u001b[1m)\u001b[0m                   Param #                   Kernel Shape\n",
       "==========================================================================================\n",
       "MLFFE_Frame                              --                        --\n",
       "├─Conv2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m1\u001b[0m                            \u001b[1;36m1\u001b[0m,\u001b[1;36m792\u001b[0m                     \u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\n",
       "├─DWTForward: \u001b[1;36m1\u001b[0m-\u001b[1;36m2\u001b[0m                        --                        --\n",
       "├─AdaptiveAvgPool2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m3\u001b[0m                 --                        --\n",
       "├─Sequential: \u001b[1;36m1\u001b[0m-\u001b[1;36m4\u001b[0m                        --                        --\n",
       "│    └─BatchNorm2d: \u001b[1;36m2\u001b[0m-\u001b[1;36m1\u001b[0m                  \u001b[1;36m1\u001b[0m,\u001b[1;36m536\u001b[0m                     --\n",
       "│    └─MaxPool2d: \u001b[1;36m2\u001b[0m-\u001b[1;36m2\u001b[0m                    --                        \u001b[1;36m2\u001b[0m\n",
       "│    └─Flatten: \u001b[1;36m2\u001b[0m-\u001b[1;36m3\u001b[0m                      --                        --\n",
       "│    └─LayerNorm: \u001b[1;36m2\u001b[0m-\u001b[1;36m4\u001b[0m                    \u001b[1;36m13\u001b[0m,\u001b[1;36m824\u001b[0m                    --\n",
       "│    └─Dropout: \u001b[1;36m2\u001b[0m-\u001b[1;36m5\u001b[0m                      --                        --\n",
       "│    └─PReLU: \u001b[1;36m2\u001b[0m-\u001b[1;36m6\u001b[0m                        \u001b[1;36m1\u001b[0m                         --\n",
       "│    └─Linear: \u001b[1;36m2\u001b[0m-\u001b[1;36m7\u001b[0m                       \u001b[1;36m3\u001b[0m,\u001b[1;36m539\u001b[0m,\u001b[1;36m456\u001b[0m                 --\n",
       "==========================================================================================\n",
       "Total params: \u001b[1;36m3\u001b[0m,\u001b[1;36m556\u001b[0m,\u001b[1;36m609\u001b[0m\n",
       "Trainable params: \u001b[1;36m3\u001b[0m,\u001b[1;36m556\u001b[0m,\u001b[1;36m609\u001b[0m\n",
       "Non-trainable params: \u001b[1;36m0\u001b[0m\n",
       "==========================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "from rich.console import Console\n",
    "\n",
    "def pretty_summary(model):\n",
    "    console = Console()\n",
    "    model_summary = summary(\n",
    "        model,\n",
    "        col_names=(\"num_params\", \"kernel_size\"),\n",
    "        depth=5,\n",
    "        verbose=0\n",
    "    )\n",
    "    console.print(model_summary)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MLFFE_Frame(embed_ch=64).to(device)\n",
    "\n",
    "pretty_summary(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(classifier.parameters()), lr=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ccb58c476f33ba3e3aee7ac07234ef6b8217ef24ad64d2a7d4fed1a57c1cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
