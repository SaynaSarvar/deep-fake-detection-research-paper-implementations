{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07174f89-1a07-4148-9ee2-a2a5ddb70ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f412ee3-251a-4322-ba3c-283bb4a915c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLCMModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, distances=[1]):\n",
    "        super().__init__()\n",
    "        self.distances = distances\n",
    "        self.angles = [0, np.pi/8, np.pi/4, 3*np.pi/8,\n",
    "                       np.pi/2, 5*np.pi/8, 3*np.pi/4, 7*np.pi/8]\n",
    "\n",
    "    def call(self, x):\n",
    "        out = tf.py_function(self._glcm_numpy, [x], Tout=tf.float32)\n",
    "        out.set_shape((None, 24))  \n",
    "        return out\n",
    "\n",
    "    def _glcm_numpy(self, x_np):\n",
    "        x_np = np.array(x_np)\n",
    "        batch_features = []\n",
    "        for sample in x_np:\n",
    "            feats = []\n",
    "            for d in range(sample.shape[2]):  # D\n",
    "                frame = sample[:, :, d, :]\n",
    "                if frame.shape[-1] == 1:\n",
    "                    gray = frame[..., 0]\n",
    "                else:\n",
    "                    gray = rgb2gray(frame)\n",
    "                gray = (gray * 255).astype(np.uint8)\n",
    "\n",
    "                glcm = graycomatrix(gray, distances=self.distances,\n",
    "                                    angles=self.angles, symmetric=True, normed=True)\n",
    "                contrast = graycoprops(glcm, 'contrast').mean()\n",
    "                dissimilarity = graycoprops(glcm, 'dissimilarity').mean()\n",
    "                homogeneity = graycoprops(glcm, 'homogeneity').mean()\n",
    "                ASM = graycoprops(glcm, 'ASM').mean()\n",
    "                energy = np.sqrt(ASM)\n",
    "                std = np.std(gray)\n",
    "                feats.extend([std, contrast, dissimilarity, homogeneity, ASM, energy])\n",
    "            batch_features.append(feats)\n",
    "        return np.array(batch_features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c574c6a-dab2-4f6f-98d4-eeb70991e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatioTemporalAttention(layers.Layer):\n",
    "    \"\"\"Simple 3D attention: mean over channels â†’ conv3d(1) â†’ sigmoid â†’ multiply\"\"\"\n",
    "    def __init__(self, kernel_size=(3,3,3)):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv3D(1, kernel_size, padding='same', use_bias=True)\n",
    "        self.act = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        att = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        att = self.conv(att)\n",
    "        att = self.act(att)\n",
    "        return x * att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af7227a-39d3-4426-bbde-dce4c8f29a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_enhanced_3d_cnn(input_shape=(128, 128, 4, 1), feature_dim=4, name='enhanced_3dcnn'):\n",
    "    \"\"\"\n",
    "    Enhanced 3D CNN architecture with spatiotemporal attention.\n",
    "    Output feature vector size = 4 .\n",
    "    \"\"\"\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "\n",
    "    # ðŸ”¹ Step 1: Spatiotemporal Attention\n",
    "    x = SpatioTemporalAttention()(inp)\n",
    "\n",
    "    # ðŸ”¹ Block 1\n",
    "    x = layers.Conv3D(8, (3, 3, 3), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool3D(pool_size=(2, 2, 1), padding='same')(x)\n",
    "\n",
    "    # ðŸ”¹ Block 2\n",
    "    x = layers.Conv3D(16, (3, 3, 3), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool3D(pool_size=(2, 2, 2), padding='same')(x)\n",
    "\n",
    "    # ðŸ”¹ Block 3\n",
    "    x = layers.Conv3D(32, (3, 3, 3), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool3D(pool_size=(2, 2, 2), padding='same')(x)\n",
    "\n",
    "    # ðŸ”¹ Block 4\n",
    "    x = layers.Conv3D(64, (3, 3, 3), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool3D(pool_size=(2, 2, 2), padding='same')(x)\n",
    "\n",
    "    # ðŸ”¹ Block 5\n",
    "    x = layers.Conv3D(128, (3, 3, 3), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool3D(pool_size=(2, 2, 2), padding='same')(x)\n",
    "\n",
    "    # ðŸ”¹ Feature extraction head\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(feature_dim, use_bias=False)(x)   \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    return tf.keras.Model(inp, x, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bbe621e-61ff-4b70-b465-acae96f5e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "    \"\"\"LBP module that forwarded to the 3d cnn\"\"\"\n",
    "class LBPCNN(tf.keras.Model):\n",
    "    def __init__(self, enhanced_cnn):\n",
    "        super().__init__()\n",
    "        self.enhanced_cnn = enhanced_cnn\n",
    "\n",
    "    def call(self, face_3d):\n",
    "        lbp_vols = tf.py_function(self._lbp_numpy, [face_3d], Tout=tf.float32)\n",
    "        lbp_vols.set_shape((None, 128, 128, 4, 1))  \n",
    "        return self.enhanced_cnn(lbp_vols)\n",
    "\n",
    "    def _lbp_numpy(self, x_np):\n",
    "        x_np = np.array(x_np)\n",
    "        lbp_vols = []\n",
    "        for sample in x_np:\n",
    "            H, W, D, C = sample.shape\n",
    "            lbp_stack = np.zeros((H, W, D, 1), dtype=np.float32)\n",
    "            for d in range(D):\n",
    "                frame = sample[:, :, d, :]\n",
    "                if frame.shape[-1] == 1:\n",
    "                    gray = frame[..., 0]\n",
    "                else:\n",
    "                    gray = rgb2gray(frame)\n",
    "                lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "                lbp_stack[:, :, d, 0] = lbp / (lbp.max() + 1e-6)\n",
    "            lbp_vols.append(lbp_stack)\n",
    "        return np.array(lbp_vols, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1df073-ea4c-4141-b04c-8c27f249b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(Model):\n",
    "    \"\"\"Shared Enhanced3DCNN for face and background\"\"\"\n",
    "    def __init__(self, shared_cnn):\n",
    "        super().__init__()\n",
    "        self.shared_cnn = shared_cnn\n",
    "\n",
    "    def call(self, inputs):\n",
    "        face_3d, back_3d = inputs\n",
    "        f_feat = self.shared_cnn(face_3d)\n",
    "        b_feat = self.shared_cnn(back_3d)\n",
    "        return f_feat, b_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658d0903-43b2-44c5-a7ca-a3c0eb930995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLPClassifier(Model):\n",
    "    \"\"\"Single dense unit with sigmoid\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8591510f-db28-4e0f-892f-29e0def52301",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepfakeDetectionModel(tf.keras.Model):\n",
    "    def __init__(self, glcm_module, lbp_cnn, siamese_net, slp_classifier):\n",
    "        super().__init__()\n",
    "        self.glcm = glcm_module\n",
    "        self.lbp_cnn = lbp_cnn\n",
    "        self.siamese = siamese_net\n",
    "        self.slp = slp_classifier\n",
    "\n",
    "    def call(self, face_3d, back_3d):\n",
    "      \n",
    "        glcm_feats = self.glcm(face_3d)\n",
    "        lbp_feats = self.lbp_cnn(face_3d)\n",
    "        face_feats, back_feats = self.siamese([face_3d, back_3d])\n",
    "        fused = tf.concat([glcm_feats, lbp_feats, face_feats, back_feats], axis=-1)\n",
    "        return self.slp(fused)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb122a5d-8027-40e2-9632-6891dc2da069",
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm_module = GLCMModule()\n",
    "enhanced_cnn = build_enhanced_3d_cnn(input_shape=(128,128,4,1), feature_dim=4)\n",
    "lbp_cnn = LBPCNN(enhanced_cnn)\n",
    "siamese_net = SiameseNetwork(enhanced_cnn)\n",
    "slp_classifier = SLPClassifier()\n",
    "\n",
    "model = DeepfakeDetectionModel(glcm_module, lbp_cnn, siamese_net, slp_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.10 (GPU)",
   "language": "python",
   "name": "tf210_gpu_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
